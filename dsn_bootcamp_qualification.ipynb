{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://gist.github.com/fachiny17/b6b5c67b5e579938643e4f12b1d855e6#file-dsn_bootcamp_qualification-ipynb",
      "authorship_tag": "ABX9TyNAVYHSNFzWkUgItACrxKG8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fachiny17/kaggle/blob/main/dsn_bootcamp_qualification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from joblib import dump"
      ],
      "metadata": {
        "id": "OKVIQ3u4zMRu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e93wEcxwcwWG",
        "outputId": "fdb85e40-604e-482e-c535-efb03a63b732"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV (update path to where your file is stored in Drive)\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/test.csv')"
      ],
      "metadata": {
        "id": "ZLkZ1XYieOoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "aar2VbTbLnB8",
        "outputId": "84378c7c-b56a-48a4-8006-7a36e5f1c2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id          brand              model  model_year  milage      fuel_type  \\\n",
              "0   0           MINI      Cooper S Base        2007  213000       Gasoline   \n",
              "1   1        Lincoln              LS V8        2002  143250       Gasoline   \n",
              "2   2      Chevrolet  Silverado 2500 LT        2002  136731  E85 Flex Fuel   \n",
              "3   3        Genesis   G90 5.0 Ultimate        2017   19500       Gasoline   \n",
              "4   4  Mercedes-Benz        Metris Base        2021    7388       Gasoline   \n",
              "\n",
              "                                              engine  \\\n",
              "0       172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel   \n",
              "1       252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel   \n",
              "2  320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...   \n",
              "3       420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel   \n",
              "4       208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel   \n",
              "\n",
              "                     transmission ext_col int_col  \\\n",
              "0                             A/T  Yellow    Gray   \n",
              "1                             A/T  Silver   Beige   \n",
              "2                             A/T    Blue    Gray   \n",
              "3  Transmission w/Dual Shift Mode   Black   Black   \n",
              "4                     7-Speed A/T   Black   Beige   \n",
              "\n",
              "                                 accident clean_title  price  \n",
              "0                           None reported         Yes   4200  \n",
              "1  At least 1 accident or damage reported         Yes   4999  \n",
              "2                           None reported         Yes  13900  \n",
              "3                           None reported         Yes  45000  \n",
              "4                           None reported         Yes  97500  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b33cd9d-8678-4b75-87bb-ce5620cc294b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>brand</th>\n",
              "      <th>model</th>\n",
              "      <th>model_year</th>\n",
              "      <th>milage</th>\n",
              "      <th>fuel_type</th>\n",
              "      <th>engine</th>\n",
              "      <th>transmission</th>\n",
              "      <th>ext_col</th>\n",
              "      <th>int_col</th>\n",
              "      <th>accident</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>MINI</td>\n",
              "      <td>Cooper S Base</td>\n",
              "      <td>2007</td>\n",
              "      <td>213000</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel</td>\n",
              "      <td>A/T</td>\n",
              "      <td>Yellow</td>\n",
              "      <td>Gray</td>\n",
              "      <td>None reported</td>\n",
              "      <td>Yes</td>\n",
              "      <td>4200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Lincoln</td>\n",
              "      <td>LS V8</td>\n",
              "      <td>2002</td>\n",
              "      <td>143250</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel</td>\n",
              "      <td>A/T</td>\n",
              "      <td>Silver</td>\n",
              "      <td>Beige</td>\n",
              "      <td>At least 1 accident or damage reported</td>\n",
              "      <td>Yes</td>\n",
              "      <td>4999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Chevrolet</td>\n",
              "      <td>Silverado 2500 LT</td>\n",
              "      <td>2002</td>\n",
              "      <td>136731</td>\n",
              "      <td>E85 Flex Fuel</td>\n",
              "      <td>320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...</td>\n",
              "      <td>A/T</td>\n",
              "      <td>Blue</td>\n",
              "      <td>Gray</td>\n",
              "      <td>None reported</td>\n",
              "      <td>Yes</td>\n",
              "      <td>13900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Genesis</td>\n",
              "      <td>G90 5.0 Ultimate</td>\n",
              "      <td>2017</td>\n",
              "      <td>19500</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel</td>\n",
              "      <td>Transmission w/Dual Shift Mode</td>\n",
              "      <td>Black</td>\n",
              "      <td>Black</td>\n",
              "      <td>None reported</td>\n",
              "      <td>Yes</td>\n",
              "      <td>45000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Mercedes-Benz</td>\n",
              "      <td>Metris Base</td>\n",
              "      <td>2021</td>\n",
              "      <td>7388</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
              "      <td>7-Speed A/T</td>\n",
              "      <td>Black</td>\n",
              "      <td>Beige</td>\n",
              "      <td>None reported</td>\n",
              "      <td>Yes</td>\n",
              "      <td>97500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b33cd9d-8678-4b75-87bb-ce5620cc294b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b33cd9d-8678-4b75-87bb-ce5620cc294b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b33cd9d-8678-4b75-87bb-ce5620cc294b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-de19567a-538e-421d-ba19-bd600396778e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de19567a-538e-421d-ba19-bd600396778e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-de19567a-538e-421d-ba19-bd600396778e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "0urqUev-nk3V",
        "outputId": "68df5029-fd81-464d-e115-4c1de8e562a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id brand                 model  model_year  milage fuel_type  \\\n",
              "0  188533  Land        Rover LR2 Base        2015   98000  Gasoline   \n",
              "1  188534  Land     Rover Defender SE        2020    9142    Hybrid   \n",
              "2  188535  Ford    Expedition Limited        2022   28121  Gasoline   \n",
              "3  188536  Audi         A6 2.0T Sport        2016   61258  Gasoline   \n",
              "4  188537  Audi  A6 2.0T Premium Plus        2018   59000  Gasoline   \n",
              "\n",
              "                                              engine        transmission  \\\n",
              "0       240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel         6-Speed A/T   \n",
              "1  395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...         8-Speed A/T   \n",
              "2                    3.5L V6 24V PDI DOHC Twin Turbo  10-Speed Automatic   \n",
              "3                                     2.0 Liter TFSI           Automatic   \n",
              "4       252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel                 A/T   \n",
              "\n",
              "           ext_col int_col       accident clean_title  \n",
              "0            White   Beige  None reported         Yes  \n",
              "1           Silver   Black  None reported         Yes  \n",
              "2            White   Ebony  None reported         NaN  \n",
              "3  Silician Yellow   Black  None reported         NaN  \n",
              "4             Gray   Black  None reported         Yes  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22253905-f1a7-47d3-89b8-57f6f60611e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>brand</th>\n",
              "      <th>model</th>\n",
              "      <th>model_year</th>\n",
              "      <th>milage</th>\n",
              "      <th>fuel_type</th>\n",
              "      <th>engine</th>\n",
              "      <th>transmission</th>\n",
              "      <th>ext_col</th>\n",
              "      <th>int_col</th>\n",
              "      <th>accident</th>\n",
              "      <th>clean_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>188533</td>\n",
              "      <td>Land</td>\n",
              "      <td>Rover LR2 Base</td>\n",
              "      <td>2015</td>\n",
              "      <td>98000</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
              "      <td>6-Speed A/T</td>\n",
              "      <td>White</td>\n",
              "      <td>Beige</td>\n",
              "      <td>None reported</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>188534</td>\n",
              "      <td>Land</td>\n",
              "      <td>Rover Defender SE</td>\n",
              "      <td>2020</td>\n",
              "      <td>9142</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n",
              "      <td>8-Speed A/T</td>\n",
              "      <td>Silver</td>\n",
              "      <td>Black</td>\n",
              "      <td>None reported</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>188535</td>\n",
              "      <td>Ford</td>\n",
              "      <td>Expedition Limited</td>\n",
              "      <td>2022</td>\n",
              "      <td>28121</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>3.5L V6 24V PDI DOHC Twin Turbo</td>\n",
              "      <td>10-Speed Automatic</td>\n",
              "      <td>White</td>\n",
              "      <td>Ebony</td>\n",
              "      <td>None reported</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>188536</td>\n",
              "      <td>Audi</td>\n",
              "      <td>A6 2.0T Sport</td>\n",
              "      <td>2016</td>\n",
              "      <td>61258</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>2.0 Liter TFSI</td>\n",
              "      <td>Automatic</td>\n",
              "      <td>Silician Yellow</td>\n",
              "      <td>Black</td>\n",
              "      <td>None reported</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>188537</td>\n",
              "      <td>Audi</td>\n",
              "      <td>A6 2.0T Premium Plus</td>\n",
              "      <td>2018</td>\n",
              "      <td>59000</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
              "      <td>A/T</td>\n",
              "      <td>Gray</td>\n",
              "      <td>Black</td>\n",
              "      <td>None reported</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22253905-f1a7-47d3-89b8-57f6f60611e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22253905-f1a7-47d3-89b8-57f6f60611e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22253905-f1a7-47d3-89b8-57f6f60611e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6973c14e-f7d0-4de9-93b6-4da5eeef654a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6973c14e-f7d0-4de9-93b6-4da5eeef654a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6973c14e-f7d0-4de9-93b6-4da5eeef654a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# file: fast_pipeline.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV, KFold\n",
        "from joblib import dump\n",
        "from scipy.stats import uniform, randint\n",
        "import warnings\n",
        "import re\n",
        "\n",
        "def create_preprocessing_pipeline():\n",
        "    numerical_feature = ['model_year', 'engine_displacement', 'milage']\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # Low-cardinality categorical features → OneHot\n",
        "    low_card_cat = ['brand', 'model', 'ext_col', 'int_col',\n",
        "                    'fuel_type', 'transmission', 'accident', 'clean_title']\n",
        "    low_card_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "    ])\n",
        "\n",
        "    # # High-cardinality categorical features → Ordinal\n",
        "    # high_card_cat = ['brand', 'model', 'ext_col', 'int_col']\n",
        "    # high_card_transformer = Pipeline(steps=[\n",
        "    #     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    #     ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "    # ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_feature),\n",
        "            ('low_cat', low_card_transformer, low_card_cat)\n",
        "            #  ('high_cat', high_card_transformer, high_card_cat)\n",
        "        ]\n",
        "    )\n",
        "    return preprocessor\n"
      ],
      "metadata": {
        "id": "zhkIdxn1e34J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    data = df.copy()\n",
        "\n",
        "    # Clean mileage\n",
        "    data['milage'] = (\n",
        "        data['milage'].astype(str).str.replace(',', '', regex=False).astype(float)\n",
        "    )\n",
        "\n",
        "    # Vectorized extraction of engine displacement\n",
        "    data['engine_displacement'] = (\n",
        "        data['engine'].astype(str).str.extract(r'(\\d+\\.?\\d*)\\s*L')[0].astype(float)\n",
        "    )\n",
        "\n",
        "    return data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PEHlOGCgfWVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_regression(y_true, y_pred):\n",
        "  \"\"\"Calculates and returns regression metrics\"\"\"\n",
        "  metrics = {\n",
        "      'MAE': mean_absolute_error(y_true, y_pred),\n",
        "      'MSE': mean_squared_error(y_true, y_pred),\n",
        "      'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
        "      \"R2\": r2_score(y_true, y_pred)\n",
        "  }\n",
        "  print(f\"Metrics: {metrics}\")\n",
        "\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "ygc95ygctOkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train_df = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "    test_df = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "    # Feature engineering\n",
        "    train_processed = extract_features(train_df)\n",
        "    test_processed = extract_features(test_df)\n",
        "\n",
        "    # Target variable\n",
        "    y_train = (\n",
        "        train_processed['price']\n",
        "        .astype(str)\n",
        "        .str.replace('$', '', regex=False)\n",
        "        .str.replace(',', '', regex=False)\n",
        "        .astype(float)\n",
        "    )\n",
        "\n",
        "    # Drop target\n",
        "    X_train = train_processed.drop(columns=['price'])\n",
        "\n",
        "    # Split training data for validation (80% train, 20% validation)\n",
        "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Build pipeline\n",
        "    preprocessor = create_preprocessing_pipeline()\n",
        "    model = HistGradientBoostingRegressor(\n",
        "        random_state=42,\n",
        "        max_iter=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=10,\n",
        "        min_samples_leaf=20,\n",
        "        l2_regularization=0.1\n",
        "    )\n",
        "\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    # # Cross-validation for RMSE evaluation\n",
        "    # kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    # cv_scores = cross_val_score(\n",
        "    #     pipeline,\n",
        "    #     X_train,\n",
        "    #     y_train,\n",
        "    #     cv=kfold,\n",
        "    #     scoring='neg_root_mean_squared_error',  # Use RMSE directly\n",
        "    #     n_jobs=-1\n",
        "    # )\n",
        "    #\n",
        "    # # Convert negative RMSE to positive (scikit-learn returns negative for scoring)\n",
        "    # rmse_scores = -cv_scores\n",
        "    # mean_rmse = rmse_scores.mean()\n",
        "    # std_rmse = rmse_scores.std()\n",
        "    #\n",
        "    # print(f\"Cross-Validation RMSE Scores: {rmse_scores}\")\n",
        "    # print(f\"Mean RMSE: {mean_rmse:.2f} ± {std_rmse:.2f}\")\n",
        "\n",
        "    # Train baseline model ------------------------------------------------------\n",
        "    print(\"Training baseline model...\")\n",
        "    baseline_model = pipeline.fit(X_train_split, y_train_split)\n",
        "    baseline_preds = baseline_model.predict(X_val)\n",
        "    baseline_metrics = evaluate_regression(y_val, baseline_preds)\n",
        "\n",
        "    # Parameter distributions for RandomizedSearchCV -------------------\n",
        "    param_distributions = {\n",
        "        'model__max_iter': randint(50, 1000),\n",
        "        'model__learning_rate': uniform(0.01, 0.3),  # 0.01 to 0.31\n",
        "        'model__max_depth': randint(3, 20),\n",
        "        'model__min_samples_leaf': randint(5, 50),\n",
        "        'model__l2_regularization': uniform(0.001, 1.0),  # 0.001 to 1.001\n",
        "        'model__max_bins': [128, 255],\n",
        "        'model__learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]\n",
        "    }\n",
        "\n",
        "\n",
        "    print(\"\\nStarting RandomizedSearchCV...\")\n",
        "    rs_model = RandomizedSearchCV(\n",
        "        estimator=pipeline,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=30,  # Try 30 random combinations (adjust as needed)\n",
        "        scoring='neg_root_mean_squared_error',\n",
        "        cv=3,  # Fewer folds for faster tuning\n",
        "        verbose=2,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    rs_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "    # Best model -------------------------------------------------------\n",
        "    print(f\"\\nBest parameters: {rs_model.best_params_}\")\n",
        "    best_model = rs_model.best_estimator_\n",
        "    rs_preds = best_model.predict(X_val)\n",
        "    rs_metrics = evaluate_regression(y_val, rs_preds)\n",
        "\n",
        "    # Compare metrics ------------------------------------------------------\n",
        "    compare_metrics = pd.DataFrame({\n",
        "        'Baseline': baseline_metrics,\n",
        "        'RandomizedSearchCV': rs_metrics\n",
        "    }).T\n",
        "    print(\"\\nModel Comparison:\")\n",
        "    print(compare_metrics)\n",
        "\n",
        "    # Final Training: Train best model on FULL training data\n",
        "    print(\"\\nTraining final model on full training data...\")\n",
        "    final_model = rs_model.best_estimator_.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on ACTUAL competition test set (no price column); make sure test_proceessed doesn't have price column\n",
        "    competition_test = test_processed.drop(columns=['price'], errors='ignore')\n",
        "    test_predictions = final_model.predict(competition_test)\n",
        "\n",
        "    # Save submission\n",
        "    submission = pd.DataFrame({\n",
        "        'id': test_df['id'],\n",
        "        'price': test_predictions\n",
        "    })\n",
        "    submission.to_csv('histgb_randomisedsearchcv.csv', index=False)\n",
        "    print(\"Submission file saved\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "LyCAhCXsfv5F",
        "outputId": "dfe3854d-0fe6-42d7-ce70-5996c4a07bf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training baseline model...\n",
            "  MAE: 19835.6606\n",
            "  RMSE: 68243.7918\n",
            "  R2: 0.1625\n",
            "\n",
            "Starting RandomizedSearchCV...\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM Regressor with preprocessing + RandomizedSearchCV\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from scipy.stats import randint, uniform\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# ---------------- Preprocessing -----------------\n",
        "def create_preprocessing_pipeline():\n",
        "    numerical_features = ['model_year', 'engine_displacement', 'milage']\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean'))\n",
        "    ])\n",
        "\n",
        "    categorical_features = ['brand', 'model', 'ext_col', 'int_col',\n",
        "                            'fuel_type', 'transmission', 'accident', 'clean_title']\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "    ])\n",
        "\n",
        "    return ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def extract_features(df):\n",
        "    data = df.copy()\n",
        "    data['milage'] = data['milage'].astype(str).str.replace(',', '', regex=False).astype(float)\n",
        "    data['engine_displacement'] = data['engine'].astype(str).str.extract(r'(\\d+\\.?\\d*)\\s*L')[0].astype(float)\n",
        "    return data\n",
        "\n",
        "def evaluate_regression(y_true, y_pred):\n",
        "    return {\n",
        "        'MAE': mean_absolute_error(y_true, y_pred),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
        "        'R2': r2_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "# ---------------- Main -----------------\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "train_processed = extract_features(train_df)\n",
        "test_processed = extract_features(test_df)\n",
        "\n",
        "y_train = train_processed['price'].astype(str).str.replace('[$,]', '', regex=True).astype(float)\n",
        "X_train = train_processed.drop(columns=['price'])\n",
        "\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', create_preprocessing_pipeline()),\n",
        "    ('model', LGBMRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "# Baseline\n",
        "print(\"Training LightGBM baseline...\")\n",
        "baseline_model = pipeline.fit(X_train_split, y_train_split)\n",
        "baseline_preds = baseline_model.predict(X_val)\n",
        "print(\"Baseline metrics:\", evaluate_regression(y_val, baseline_preds))\n",
        "\n",
        "# Param space\n",
        "param_dist = {\n",
        "    'model__n_estimators': randint(100, 1000),\n",
        "    'model__learning_rate': uniform(0.01, 0.3),\n",
        "    'model__max_depth': randint(3, 20),\n",
        "    'model__num_leaves': randint(20, 200),\n",
        "    'model__min_child_samples': randint(5, 100)\n",
        "}\n",
        "\n",
        "# RandomizedSearch\n",
        "print(\"\\nTuning LightGBM with RandomizedSearchCV...\")\n",
        "rs = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=30,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "rs.fit(X_train_split, y_train_split)\n",
        "\n",
        "print(\"Best params:\", rs.best_params_)\n",
        "\n",
        "# Evaluate best model\n",
        "val_preds = rs.predict(X_val)\n",
        "print(\"Validation metrics:\", evaluate_regression(y_val, val_preds))\n",
        "\n",
        "# Final model on full data\n",
        "final_model = rs.best_estimator_.fit(X_train, y_train)\n",
        "competition_test = test_processed.drop(columns=['price'], errors='ignore')\n",
        "test_preds = final_model.predict(competition_test)\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({'id': test_df['id'], 'price': test_preds})\n",
        "submission.to_csv('lightgbm_submission.csv', index=False)\n",
        "print(\"LightGBM submission saved!\")"
      ],
      "metadata": {
        "id": "tT8vzkrNb90c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "outputId": "6216e928-29c8-4362-c1b3-b9077f2586ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training LightGBM baseline...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.683314 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4012\n",
            "[LightGBM] [Info] Number of data points in the train set: 169679, number of used features: 1833\n",
            "[LightGBM] [Info] Start training from score 43888.560718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline metrics: {'MAE': 19695.47160267817, 'RMSE': np.float64(69699.18035558485), 'R2': 0.15165160352832463}\n",
            "\n",
            "Tuning LightGBM with RandomizedSearchCV...\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2224409312.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m )\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best params:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1952\u001b[0m             ParameterSampler(\n\u001b[1;32m   1953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def extract_features(df):\n",
        "    \"\"\"Simple feature engineering\"\"\"\n",
        "    data = df.copy()\n",
        "\n",
        "    # Clean milage (correct spelling)\n",
        "    if 'milage' in data.columns:\n",
        "        data['milage'] = data['milage'].astype(str).str.replace(',', '').astype(float)\n",
        "\n",
        "    # Extract engine displacement if engine column exists\n",
        "    if 'engine' in data.columns:\n",
        "        # Try to extract numeric value from engine description\n",
        "        data['engine_displacement'] = (\n",
        "            data['engine']\n",
        "            .astype(str)\n",
        "            .str.extract(r'(\\d+\\.?\\d*)')[0]  # Extract first numeric value\n",
        "            .astype(float)\n",
        "        )\n",
        "\n",
        "    return data\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    train_df = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "    test_df = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "    # Feature engineering\n",
        "    train_processed = extract_features(train_df)\n",
        "    test_processed = extract_features(test_df)\n",
        "\n",
        "    # Target variable\n",
        "    y_train = (\n",
        "        train_processed['price']\n",
        "        .astype(str)\n",
        "        .str.replace('$', '', regex=False)\n",
        "        .str.replace(',', '', regex=False)\n",
        "        .astype(float)\n",
        "    )\n",
        "\n",
        "    # Features - drop price and keep important columns\n",
        "    feature_cols = ['model_year', 'milage', 'brand', 'model', 'fuel_type', 'transmission']\n",
        "    X_train = train_processed[feature_cols]\n",
        "    X_test = test_processed[feature_cols]\n",
        "\n",
        "    # Encode categorical variables for LightGBM\n",
        "    categorical_cols = ['brand', 'model', 'fuel_type', 'transmission']\n",
        "    label_encoders = {}\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        if col in X_train.columns:\n",
        "            le = LabelEncoder()\n",
        "            # Combine train and test for consistent encoding\n",
        "            combined = pd.concat([X_train[col], X_test[col]], axis=0)\n",
        "            le.fit(combined.astype(str))\n",
        "            X_train[col] = le.transform(X_train[col].astype(str))\n",
        "            X_test[col] = le.transform(X_test[col].astype(str))\n",
        "            label_encoders[col] = le\n",
        "\n",
        "    # Handle missing values\n",
        "    X_train = X_train.fillna(X_train.median())\n",
        "    X_test = X_test.fillna(X_test.median())\n",
        "\n",
        "    # Train-validation split\n",
        "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # LightGBM model with early stopping in constructor\n",
        "    print(\"Training LightGBM model...\")\n",
        "    model = lgb.LGBMRegressor(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=7,\n",
        "        num_leaves=31,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1,\n",
        "        early_stopping_rounds=50  # CORRECTED: moved to constructor\n",
        "    )\n",
        "\n",
        "    # Train with early stopping - CORRECTED syntax\n",
        "    model.fit(\n",
        "        X_train_split,\n",
        "        y_train_split,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_metric='rmse'\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    val_preds = model.predict(X_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
        "    mae = mean_absolute_error(y_val, val_preds)\n",
        "    r2 = r2_score(y_val, val_preds)\n",
        "\n",
        "    print(f\"Validation RMSE: {rmse:.2f}\")\n",
        "    print(f\"Validation MAE: {mae:.2f}\")\n",
        "    print(f\"Validation R²: {r2:.4f}\")\n",
        "\n",
        "    # Final training on full data\n",
        "    print(\"\\nTraining final model on full data...\")\n",
        "    final_model = lgb.LGBMRegressor(\n",
        "        n_estimators=model.best_iteration_ if hasattr(model, 'best_iteration_') else 1000,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=7,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1\n",
        "    )\n",
        "    final_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test set\n",
        "    test_predictions = final_model.predict(X_test)\n",
        "\n",
        "    # Save submission\n",
        "    submission = pd.DataFrame({\n",
        "        'id': test_df['id'],\n",
        "        'price': test_predictions\n",
        "    })\n",
        "    submission.to_csv('lightgbm_submission.csv', index=False)\n",
        "    print(\"✅ LightGBM submission file saved!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft8wQJkvgnoK",
        "outputId": "7bdeacc6-6cdd-466b-8d13-2aba3526388e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training LightGBM model...\n",
            "Validation RMSE: 68229.69\n",
            "Validation MAE: 20052.95\n",
            "Validation R²: 0.1629\n",
            "\n",
            "Training final model on full data...\n",
            "✅ LightGBM submission file saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.stats import randint, uniform\n",
        "import warnings\n",
        "import re\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def enhanced_extract_features(df):\n",
        "    \"\"\"Advanced feature engineering\"\"\"\n",
        "    data = df.copy()\n",
        "\n",
        "    # Clean milage\n",
        "    if 'milage' in data.columns:\n",
        "        data['milage'] = data['milage'].astype(str).str.replace(',', '').astype(float)\n",
        "\n",
        "    # Extract engine features if available\n",
        "    if 'engine' in data.columns:\n",
        "        # Extract displacement\n",
        "        displacement = data['engine'].astype(str).str.extract(r'(\\d+\\.?\\d*)\\s*L')[0]\n",
        "        data['engine_displacement'] = pd.to_numeric(displacement, errors='coerce')\n",
        "\n",
        "        # Extract cylinders if mentioned\n",
        "        cylinders = data['engine'].str.extract(r'(\\d+)\\s*cyl', flags=re.IGNORECASE)[0]\n",
        "        data['cylinders'] = pd.to_numeric(cylinders, errors='coerce')\n",
        "\n",
        "        # Engine type features\n",
        "        data['is_v6'] = data['engine'].str.contains('v6', case=False).astype(int)\n",
        "        data['is_v8'] = data['engine'].str.contains('v8', case=False).astype(int)\n",
        "\n",
        "    # Extract year from model year if it's a string\n",
        "    if 'model_year' in data.columns:\n",
        "        if data['model_year'].dtype == 'object':\n",
        "            data['model_year'] = data['model_year'].str.extract(r'(\\d{4})')[0].astype(float)\n",
        "        data['model_year'] = pd.to_numeric(data['model_year'], errors='coerce')\n",
        "        data['car_age'] = 2024 - data['model_year']  # Assuming current year is 2024\n",
        "\n",
        "    # Create interaction features\n",
        "    if all(col in data.columns for col in ['milage', 'car_age']):\n",
        "        data['miles_per_year'] = data['milage'] / np.maximum(1, data['car_age'])\n",
        "\n",
        "    # Price-based features (for training data only)\n",
        "    if 'price' in data.columns:\n",
        "        data['price'] = data['price'].astype(str).str.replace(r'[^\\d.]', '', regex=True).astype(float)\n",
        "\n",
        "    return data\n",
        "\n",
        "def create_additional_features(X, y=None):\n",
        "    \"\"\"Create additional engineered features\"\"\"\n",
        "    X = X.copy()\n",
        "\n",
        "    # Brand-model combination\n",
        "    if all(col in X.columns for col in ['brand', 'model']):\n",
        "        X['brand_model'] = X['brand'].astype(str) + '_' + X['model'].astype(str)\n",
        "\n",
        "    # Fuel-transmission combination\n",
        "    if all(col in X.columns for col in ['fuel_type', 'transmission']):\n",
        "        X['fuel_transmission'] = X['fuel_type'].astype(str) + '_' + X['transmission'].astype(str)\n",
        "\n",
        "    return X\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    train_df = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "    test_df = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "    # Enhanced feature engineering\n",
        "    print(\"Performing advanced feature engineering...\")\n",
        "    train_processed = enhanced_extract_features(train_df)\n",
        "    test_processed = enhanced_extract_features(test_df)\n",
        "\n",
        "    # Target variable\n",
        "    y_train = (\n",
        "        train_processed['price']\n",
        "        .astype(str)\n",
        "        .str.replace(r'[^\\d.]', '', regex=True)\n",
        "        .astype(float)\n",
        "    )\n",
        "\n",
        "    # Drop target and ID columns\n",
        "    X_train = train_processed.drop(columns=['price'], errors='ignore')\n",
        "    X_test = test_processed.drop(columns=['price'], errors='ignore')\n",
        "\n",
        "    # Create additional features\n",
        "    X_train = create_additional_features(X_train, y_train)\n",
        "    X_test = create_additional_features(X_test)\n",
        "\n",
        "    # Select the most important features\n",
        "    feature_cols = [\n",
        "        'model_year', 'milage', 'car_age', 'miles_per_year', 'engine_displacement',\n",
        "        'cylinders', 'is_v6', 'is_v8', 'brand', 'model', 'fuel_type', 'transmission',\n",
        "        'accident', 'clean_title', 'brand_model', 'fuel_transmission'\n",
        "    ]\n",
        "    # Keep only columns that exist\n",
        "    feature_cols = [col for col in feature_cols if col in X_train.columns]\n",
        "\n",
        "    X_train = X_train[feature_cols]\n",
        "    X_test = X_test[feature_cols]\n",
        "\n",
        "    # Encode categorical variables\n",
        "    categorical_cols = ['brand', 'model', 'fuel_type', 'transmission', 'brand_model', 'fuel_transmission']\n",
        "    categorical_cols = [col for col in categorical_cols if col in X_train.columns]\n",
        "\n",
        "    label_encoders = {}\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        # Combine train and test for consistent encoding\n",
        "        combined = pd.concat([X_train[col].astype(str), X_test[col].astype(str)])\n",
        "        le.fit(combined)\n",
        "        X_train[col] = le.transform(X_train[col].astype(str))\n",
        "        X_test[col] = le.transform(X_test[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    # Handle missing values\n",
        "    for df in [X_train, X_test]:\n",
        "        for col in df.columns:\n",
        "            if df[col].dtype in ['int64', 'float64']:\n",
        "                df[col].fillna(df[col].median(), inplace=True)\n",
        "            else:\n",
        "                df[col].fillna(0, inplace=True)\n",
        "\n",
        "    # Train-validation split\n",
        "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.15, random_state=42  # Smaller validation set\n",
        "    )\n",
        "\n",
        "    # Hyperparameter tuning with RandomizedSearchCV\n",
        "    print(\"Performing hyperparameter tuning...\")\n",
        "    param_distributions = {\n",
        "        'n_estimators': randint(300, 1200),\n",
        "        'learning_rate': uniform(0.01, 0.2),\n",
        "        'max_depth': randint(5, 15),\n",
        "        'num_leaves': randint(20, 100),\n",
        "        'subsample': uniform(0.6, 0.4),  # 0.6 to 1.0\n",
        "        'colsample_bytree': uniform(0.6, 0.4),\n",
        "        'reg_alpha': uniform(0, 1),\n",
        "        'reg_lambda': uniform(0, 1),\n",
        "        'min_child_samples': randint(5, 50)\n",
        "    }\n",
        "\n",
        "    # Base model\n",
        "    base_model = lgb.LGBMRegressor(\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    # Randomized search with few iterations for speed\n",
        "    rs_model = RandomizedSearchCV(\n",
        "        estimator=base_model,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=15,  # More iterations for better results\n",
        "        scoring='neg_root_mean_squared_error',\n",
        "        cv=3,\n",
        "        verbose=1,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    rs_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "    print(f\"Best parameters: {rs_model.best_params_}\")\n",
        "    print(f\"Best CV score: {-rs_model.best_score_:.2f}\")\n",
        "\n",
        "    # Train final model with best parameters\n",
        "    print(\"\\nTraining final optimized model...\")\n",
        "    best_params = rs_model.best_params_\n",
        "\n",
        "    final_model = lgb.LGBMRegressor(\n",
        "        **best_params,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    # Train on full training split\n",
        "    final_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_preds = final_model.predict(X_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
        "    mae = mean_absolute_error(y_val, val_preds)\n",
        "    r2 = r2_score(y_val, val_preds)\n",
        "\n",
        "    print(f\"✅ Validation RMSE: {rmse:.2f}\")\n",
        "    print(f\"✅ Validation MAE: {mae:.2f}\")\n",
        "    print(f\"✅ Validation R²: {r2:.4f}\")\n",
        "\n",
        "    # Feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X_train.columns,\n",
        "        'importance': final_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\n📊 Top 10 Feature Importance:\")\n",
        "    print(feature_importance.head(10))\n",
        "\n",
        "    # Final training on FULL dataset with best parameters\n",
        "    print(\"\\n🎯 Training on full dataset for submission...\")\n",
        "    final_submission_model = lgb.LGBMRegressor(\n",
        "        **best_params,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    final_submission_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test set\n",
        "    test_predictions = final_submission_model.predict(X_test)\n",
        "\n",
        "    # Apply post-processing (ensure no negative prices)\n",
        "    test_predictions = np.maximum(test_predictions, 0)\n",
        "\n",
        "    # Save submission\n",
        "    submission = pd.DataFrame({\n",
        "        'id': test_df['id'],\n",
        "        'price': test_predictions\n",
        "    })\n",
        "    submission.to_csv('lightgbm_optimized_submission.csv', index=False)\n",
        "    print(\"✅ Optimized LightGBM submission file saved!\")\n",
        "\n",
        "    # Show prediction statistics\n",
        "    print(f\"\\n📈 Prediction Statistics:\")\n",
        "    print(f\"Min price: ${test_predictions.min():.2f}\")\n",
        "    print(f\"Max price: ${test_predictions.max():.2f}\")\n",
        "    print(f\"Mean price: ${test_predictions.mean():.2f}\")\n",
        "    print(f\"Median price: ${np.median(test_predictions):.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "PzsXha1zk603",
        "outputId": "168a7517-46b5-420e-af98-5403f39bbe89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Performing advanced feature engineering...\n",
            "Performing hyperparameter tuning...\n",
            "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/sklearn.py\", line 1398, in fit\n    super().fit(\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/sklearn.py\", line 1049, in fit\n    self._Booster = train(\n                    ^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/engine.py\", line 297, in train\n    booster = Booster(params=params, train_set=train_set)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 3656, in __init__\n    train_set.construct()\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2590, in construct\n    self._lazy_init(\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2123, in _lazy_init\n    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n                                                                       ^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 868, in _data_from_pandas\n    _pandas_to_numpy(data, target_dtype=target_dtype),\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 814, in _pandas_to_numpy\n    _check_for_bad_pandas_dtypes(data.dtypes)\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 805, in _check_for_bad_pandas_dtypes\n    raise ValueError(\nValueError: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: accident: object, clean_title: object\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2391195406.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2391195406.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mrs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best parameters: {rs_model.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1952\u001b[0m             ParameterSampler(\n\u001b[1;32m   1953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    999\u001b[0m                     )\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             )\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/sklearn.py\", line 1398, in fit\n    super().fit(\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/sklearn.py\", line 1049, in fit\n    self._Booster = train(\n                    ^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/engine.py\", line 297, in train\n    booster = Booster(params=params, train_set=train_set)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 3656, in __init__\n    train_set.construct()\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2590, in construct\n    self._lazy_init(\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2123, in _lazy_init\n    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n                                                                       ^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 868, in _data_from_pandas\n    _pandas_to_numpy(data, target_dtype=target_dtype),\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 814, in _pandas_to_numpy\n    _check_for_bad_pandas_dtypes(data.dtypes)\n  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 805, in _check_for_bad_pandas_dtypes\n    raise ValueError(\nValueError: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: accident: object, clean_title: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.stats import randint, uniform\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def enhanced_extract_features(df):\n",
        "    \"\"\"Advanced feature engineering with robust handling\"\"\"\n",
        "    data = df.copy()\n",
        "\n",
        "    # Clean milage\n",
        "    if 'milage' in data.columns:\n",
        "        data['milage'] = data['milage'].astype(str).str.replace(',', '').astype(float)\n",
        "\n",
        "    # Extract engine features if available\n",
        "    if 'engine' in data.columns:\n",
        "        # Extract displacement\n",
        "        displacement = data['engine'].astype(str).str.extract(r'(\\d+\\.?\\d*)\\s*L')[0]\n",
        "        data['engine_displacement'] = pd.to_numeric(displacement, errors='coerce')\n",
        "\n",
        "    # Extract year from model year\n",
        "    if 'model_year' in data.columns:\n",
        "        if data['model_year'].dtype == 'object':\n",
        "            data['model_year'] = data['model_year'].str.extract(r'(\\d{4})')[0].astype(float)\n",
        "        data['model_year'] = pd.to_numeric(data['model_year'], errors='coerce')\n",
        "        data['car_age'] = 2024 - data['model_year']\n",
        "\n",
        "    # Create interaction features\n",
        "    if all(col in data.columns for col in ['milage', 'car_age']):\n",
        "        data['miles_per_year'] = data['milage'] / np.maximum(1, data['car_age'])\n",
        "\n",
        "    # Handle boolean/yes-no columns properly\n",
        "    bool_columns = ['accident', 'clean_title']\n",
        "    for col in bool_columns:\n",
        "        if col in data.columns:\n",
        "            # Convert to numeric (1 for yes/true, 0 for no/false)\n",
        "            data[col] = data[col].astype(str).str.lower().map({'yes': 1, 'true': 1, '1': 1, 'no': 0, 'false': 0, '0': 0}).fillna(0).astype(int)\n",
        "\n",
        "    # Price cleaning\n",
        "    if 'price' in data.columns:\n",
        "        data['price'] = data['price'].astype(str).str.replace(r'[^\\d.]', '', regex=True).astype(float)\n",
        "\n",
        "    return data\n",
        "\n",
        "def create_additional_features(X):\n",
        "    \"\"\"Create additional engineered features\"\"\"\n",
        "    X = X.copy()\n",
        "\n",
        "    # Brand-model combination\n",
        "    if all(col in X.columns for col in ['brand', 'model']):\n",
        "        X['brand_model'] = X['brand'].astype(str) + '_' + X['model'].astype(str)\n",
        "\n",
        "    return X\n",
        "\n",
        "def prepare_features(X_train, X_test):\n",
        "    \"\"\"Prepare features for LightGBM with proper encoding\"\"\"\n",
        "    # Select numeric features\n",
        "    numeric_features = ['model_year', 'milage', 'car_age', 'miles_per_year', 'engine_displacement']\n",
        "    numeric_features = [col for col in numeric_features if col in X_train.columns]\n",
        "\n",
        "    # Select categorical features (excluding boolean ones that are already numeric)\n",
        "    categorical_features = ['brand', 'model', 'fuel_type', 'transmission', 'brand_model']\n",
        "    categorical_features = [col for col in categorical_features if col in X_train.columns]\n",
        "\n",
        "    # Select boolean features (already converted to 0/1)\n",
        "    boolean_features = ['accident', 'clean_title']\n",
        "    boolean_features = [col for col in boolean_features if col in X_train.columns]\n",
        "\n",
        "    # Combine all features\n",
        "    all_features = numeric_features + categorical_features + boolean_features\n",
        "\n",
        "    # Prepare train and test data\n",
        "    X_train_prepared = X_train[all_features].copy()\n",
        "    X_test_prepared = X_test[all_features].copy()\n",
        "\n",
        "    # Encode categorical variables\n",
        "    label_encoders = {}\n",
        "    for col in categorical_features:\n",
        "        le = LabelEncoder()\n",
        "        # Combine train and test for consistent encoding\n",
        "        combined = pd.concat([X_train_prepared[col].astype(str), X_test_prepared[col].astype(str)])\n",
        "        le.fit(combined)\n",
        "        X_train_prepared[col] = le.transform(X_train_prepared[col].astype(str))\n",
        "        X_test_prepared[col] = le.transform(X_test_prepared[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    # Handle missing values\n",
        "    for df in [X_train_prepared, X_test_prepared]:\n",
        "        for col in df.columns:\n",
        "            if df[col].dtype in ['int64', 'float64']:\n",
        "                df[col].fillna(df[col].median(), inplace=True)\n",
        "            else:\n",
        "                df[col].fillna(0, inplace=True)\n",
        "\n",
        "    return X_train_prepared, X_test_prepared, label_encoders\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    train_df = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "    test_df = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "    # Enhanced feature engineering\n",
        "    print(\"Performing advanced feature engineering...\")\n",
        "    train_processed = enhanced_extract_features(train_df)\n",
        "    test_processed = enhanced_extract_features(test_df)\n",
        "\n",
        "    # Target variable\n",
        "    y_train = train_processed['price'].copy()\n",
        "\n",
        "    # Drop target and ID columns\n",
        "    X_train = train_processed.drop(columns=['price'], errors='ignore')\n",
        "    X_test = test_processed.drop(columns=['price'], errors='ignore')\n",
        "\n",
        "    # Create additional features\n",
        "    X_train = create_additional_features(X_train)\n",
        "    X_test = create_additional_features(X_test)\n",
        "\n",
        "    # Prepare features for LightGBM\n",
        "    print(\"Preparing features for modeling...\")\n",
        "    X_train_prepared, X_test_prepared, label_encoders = prepare_features(X_train, X_test)\n",
        "\n",
        "    # Train-validation split\n",
        "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "        X_train_prepared, y_train, test_size=0.15, random_state=42\n",
        "    )\n",
        "\n",
        "    # SIMPLIFIED Hyperparameter tuning - start with basic model first\n",
        "    print(\"Training initial model...\")\n",
        "    base_model = lgb.LGBMRegressor(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=7,\n",
        "        num_leaves=31,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    # First train a simple model to ensure it works\n",
        "    base_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "    # Evaluate initial model\n",
        "    val_preds = base_model.predict(X_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
        "    print(f\"✅ Initial Validation RMSE: {rmse:.2f}\")\n",
        "\n",
        "    # Now try limited hyperparameter tuning\n",
        "    print(\"Performing limited hyperparameter tuning...\")\n",
        "    param_distributions = {\n",
        "        'n_estimators': [300, 500, 700],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [5, 7, 9],\n",
        "        'num_leaves': [31, 63],\n",
        "        'subsample': [0.8, 0.9],\n",
        "    }\n",
        "\n",
        "    rs_model = RandomizedSearchCV(\n",
        "        estimator=lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1),\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=8,  # Few iterations for stability\n",
        "        scoring='neg_root_mean_squared_error',\n",
        "        cv=2,  # Fewer folds\n",
        "        verbose=1,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    rs_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "    print(f\"Best parameters: {rs_model.best_params_}\")\n",
        "    print(f\"Best CV score: {-rs_model.best_score_:.2f}\")\n",
        "\n",
        "    # Train final model with best parameters\n",
        "    print(\"\\nTraining final optimized model...\")\n",
        "    best_params = rs_model.best_params_\n",
        "\n",
        "    final_model = lgb.LGBMRegressor(\n",
        "        **best_params,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    final_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_preds = final_model.predict(X_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
        "    mae = mean_absolute_error(y_val, val_preds)\n",
        "    r2 = r2_score(y_val, val_preds)\n",
        "\n",
        "    print(f\"✅ Final Validation RMSE: {rmse:.2f}\")\n",
        "    print(f\"✅ Final Validation MAE: {mae:.2f}\")\n",
        "    print(f\"✅ Final Validation R²: {r2:.4f}\")\n",
        "\n",
        "    # Final training on FULL dataset\n",
        "    print(\"\\n🎯 Training on full dataset for submission...\")\n",
        "    final_submission_model = lgb.LGBMRegressor(\n",
        "        **best_params,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    final_submission_model.fit(X_train_prepared, y_train)\n",
        "\n",
        "    # Predict on test set\n",
        "    test_predictions = final_submission_model.predict(X_test_prepared)\n",
        "    test_predictions = np.maximum(test_predictions, 0)  # No negative prices\n",
        "\n",
        "    # Save submission\n",
        "    submission = pd.DataFrame({\n",
        "        'id': test_df['id'],\n",
        "        'price': test_predictions\n",
        "    })\n",
        "    submission.to_csv('lightgbm_optimized_submission.csv', index=False)\n",
        "    print(\"✅ Optimized LightGBM submission file saved!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "MBQev35pmdFi",
        "outputId": "9663aba4-172c-4e19-e5c5-8d621e665453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Performing advanced feature engineering...\n",
            "Preparing features for modeling...\n",
            "Training initial model...\n",
            "✅ Initial Validation RMSE: 67808.08\n",
            "Performing limited hyperparameter tuning...\n",
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "Best parameters: {'subsample': 0.8, 'num_leaves': 63, 'n_estimators': 700, 'max_depth': 5, 'learning_rate': 0.01}\n",
            "Best CV score: 74018.26\n",
            "\n",
            "Training final optimized model...\n",
            "✅ Final Validation RMSE: 67229.32\n",
            "✅ Final Validation MAE: 19491.80\n",
            "✅ Final Validation R²: 0.1653\n",
            "\n",
            "🎯 Training on full dataset for submission...\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "✅ Optimized LightGBM submission file saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.stats import randint, uniform, loguniform\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "def elite_feature_engineering(df):\n",
        "    \"\"\"Elite feature engineering with robust type handling\"\"\"\n",
        "    data = df.copy()\n",
        "\n",
        "    # === PRICE CLEANING ===\n",
        "    if 'price' in data.columns:\n",
        "        data['price'] = (\n",
        "            data['price']\n",
        "            .astype(str)\n",
        "            .str.replace(r'[^\\d.]', '', regex=True)\n",
        "            .astype(float)\n",
        "        )\n",
        "\n",
        "    # === MILEAGE ENHANCEMENT ===\n",
        "    if 'milage' in data.columns:\n",
        "        data['milage'] = (\n",
        "            data['milage']\n",
        "            .astype(str)\n",
        "            .str.replace(',', '')\n",
        "            .replace('', np.nan)\n",
        "            .astype(float)\n",
        "        )\n",
        "        # Create mileage features\n",
        "        data['mileage_log'] = np.log1p(data['milage'].fillna(0))\n",
        "        data['mileage_bin'] = pd.qcut(data['milage'], q=5, labels=False, duplicates='drop')\n",
        "\n",
        "    # === ENGINE FEATURE EXTRACTION ===\n",
        "    if 'engine' in data.columns:\n",
        "        # Multiple extraction patterns\n",
        "        patterns = {\n",
        "            'displacement': r'(\\d+\\.?\\d*)\\s*L',\n",
        "            'cylinders': r'(\\d+)\\s*cyl',\n",
        "            'horsepower': r'(\\d+)\\s*HP'\n",
        "        }\n",
        "\n",
        "        for feature, pattern in patterns.items():\n",
        "            extracted = data['engine'].astype(str).str.extract(pattern, flags=re.IGNORECASE)[0]\n",
        "            if not extracted.isna().all():\n",
        "                data[f'engine_{feature}'] = pd.to_numeric(extracted, errors='coerce')\n",
        "\n",
        "        # Boolean engine features\n",
        "        data['engine_turbo'] = data['engine'].astype(str).str.contains('turbo', case=False, na=False).astype(int)\n",
        "        data['engine_v6'] = data['engine'].astype(str).str.contains('v6', case=False, na=False).astype(int)\n",
        "        data['engine_v8'] = data['engine'].astype(str).str.contains('v8', case=False, na=False).astype(int)\n",
        "\n",
        "    # === MODEL YEAR ENHANCEMENT ===\n",
        "    if 'model_year' in data.columns:\n",
        "        data['model_year'] = pd.to_numeric(data['model_year'], errors='coerce')\n",
        "        data['car_age'] = 2024 - data['model_year'].fillna(2000)\n",
        "        data['is_modern'] = (data['model_year'] >= 2015).astype(int)\n",
        "        data['is_classic'] = (data['model_year'] <= 2000).astype(int)\n",
        "\n",
        "    # === BOOLEAN COLUMNS ===\n",
        "    bool_columns = ['accident', 'clean_title']\n",
        "    for col in bool_columns:\n",
        "        if col in data.columns:\n",
        "            data[col] = (\n",
        "                data[col]\n",
        "                .astype(str)\n",
        "                .str.lower()\n",
        "                .map({'yes': 1, 'true': 1, '1': 1, 'y': 1, 'no': 0, 'false': 0, '0': 0, 'n': 0})\n",
        "                .fillna(0)\n",
        "                .astype(int)\n",
        "            )\n",
        "\n",
        "    # === INTERACTION FEATURES ===\n",
        "    if all(col in data.columns for col in ['milage', 'car_age']):\n",
        "        data['miles_per_year'] = data['milage'] / np.maximum(1, data['car_age'])\n",
        "\n",
        "    # === BRAND AND MODEL FEATURES ===\n",
        "    if 'brand' in data.columns:\n",
        "        data['brand'] = data['brand'].str.upper().str.strip()\n",
        "\n",
        "    return data\n",
        "\n",
        "def create_advanced_features(X):\n",
        "    \"\"\"Create advanced feature combinations\"\"\"\n",
        "    X = X.copy()\n",
        "\n",
        "    # Brand-Model combination\n",
        "    if all(col in X.columns for col in ['brand', 'model']):\n",
        "        X['brand_model'] = X['brand'].astype(str) + '_' + X['model'].astype(str)\n",
        "\n",
        "    return X\n",
        "\n",
        "def prepare_elite_features(X_train, X_test, y_train=None):\n",
        "    \"\"\"Elite feature preparation with robust type handling\"\"\"\n",
        "    # Define feature categories - ONLY NUMERIC FEATURES\n",
        "    numeric_features = [\n",
        "        'model_year', 'milage', 'mileage_log', 'car_age', 'miles_per_year',\n",
        "        'engine_displacement', 'engine_cylinders', 'engine_horsepower',\n",
        "        'engine_turbo', 'engine_v6', 'engine_v8', 'is_modern', 'is_classic',\n",
        "        'accident', 'clean_title'\n",
        "    ]\n",
        "\n",
        "    categorical_features = [\n",
        "        'brand', 'model', 'fuel_type', 'transmission', 'brand_model'\n",
        "    ]\n",
        "\n",
        "    # Select only existing features\n",
        "    numeric_features = [col for col in numeric_features if col in X_train.columns]\n",
        "    categorical_features = [col for col in categorical_features if col in X_train.columns]\n",
        "\n",
        "    all_features = numeric_features + categorical_features\n",
        "\n",
        "    # Prepare data\n",
        "    X_train_prepared = X_train[all_features].copy()\n",
        "    X_test_prepared = X_test[all_features].copy()\n",
        "\n",
        "    # Ensure all numeric features are actually numeric\n",
        "    for col in numeric_features:\n",
        "        if col in X_train_prepared.columns:\n",
        "            X_train_prepared[col] = pd.to_numeric(X_train_prepared[col], errors='coerce')\n",
        "            X_test_prepared[col] = pd.to_numeric(X_test_prepared[col], errors='coerce')\n",
        "\n",
        "    # Smart encoding for categorical features\n",
        "    label_encoders = {}\n",
        "    for col in categorical_features:\n",
        "        le = LabelEncoder()\n",
        "        combined = pd.concat([X_train_prepared[col].astype(str), X_test_prepared[col].astype(str)])\n",
        "        le.fit(combined)\n",
        "        X_train_prepared[col] = le.transform(X_train_prepared[col].astype(str))\n",
        "        X_test_prepared[col] = le.transform(X_test_prepared[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    # Handle missing values\n",
        "    for df in [X_train_prepared, X_test_prepared]:\n",
        "        for col in df.columns:\n",
        "            if df[col].dtype in ['int64', 'float64']:\n",
        "                df[col].fillna(df[col].median(), inplace=True)\n",
        "            else:\n",
        "                df[col].fillna(0, inplace=True)\n",
        "\n",
        "    return X_train_prepared, X_test_prepared, label_encoders\n",
        "\n",
        "def main():\n",
        "    print(\"🚀 Starting ROBUST LightGBM Modeling...\")\n",
        "\n",
        "    # Load data\n",
        "    train_df = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "    test_df = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "    # Elite feature engineering\n",
        "    print(\"🔧 Performing robust feature engineering...\")\n",
        "    train_processed = elite_feature_engineering(train_df)\n",
        "    test_processed = elite_feature_engineering(test_df)\n",
        "\n",
        "    # Target variable\n",
        "    y_train = train_processed['price'].copy()\n",
        "\n",
        "    # Drop target and ID columns\n",
        "    X_train = train_processed.drop(columns=['price'], errors='ignore')\n",
        "    X_test = test_processed.drop(columns=['price'], errors='ignore')\n",
        "\n",
        "    # Create advanced features\n",
        "    X_train = create_advanced_features(X_train)\n",
        "    X_test = create_advanced_features(X_test)\n",
        "\n",
        "    # Prepare elite features\n",
        "    print(\"⚙️ Preparing robust features...\")\n",
        "    X_train_prepared, X_test_prepared, label_encoders = prepare_elite_features(X_train, X_test, y_train)\n",
        "\n",
        "    # Ensure all data is numeric\n",
        "    print(\"✅ Data types in prepared features:\")\n",
        "    print(X_train_prepared.dtypes.value_counts())\n",
        "\n",
        "    # Train-validation split\n",
        "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "        X_train_prepared, y_train, test_size=0.1, random_state=42, shuffle=True\n",
        "    )\n",
        "\n",
        "    # === SIMPLIFIED BUT EFFECTIVE TUNING ===\n",
        "    print(\"🎯 Performing efficient hyperparameter tuning...\")\n",
        "\n",
        "    param_distributions = {\n",
        "        'n_estimators': [500, 800, 1000],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [6, 8, 10],\n",
        "        'num_leaves': [31, 63, 127],\n",
        "        'min_child_samples': [20, 50, 100],\n",
        "        'subsample': [0.7, 0.8, 0.9],\n",
        "        'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "        'reg_alpha': [0.1, 0.5, 1.0],\n",
        "        'reg_lambda': [0.1, 0.5, 1.0],\n",
        "    }\n",
        "\n",
        "    # Use simpler validation\n",
        "    robust_model = RandomizedSearchCV(\n",
        "        estimator=lgb.LGBMRegressor(\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            verbose=-1,\n",
        "            metric='rmse'\n",
        "        ),\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=15,  # Reduced iterations for stability\n",
        "        scoring='neg_root_mean_squared_error',\n",
        "        cv=3,\n",
        "        verbose=2,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    robust_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "    print(f\"🏆 Best parameters: {robust_model.best_params_}\")\n",
        "    print(f\"🏆 Best CV score: {-robust_model.best_score_:.2f}\")\n",
        "\n",
        "    # === ROBUST MODEL TRAINING ===\n",
        "    print(\"\\n🔥 Training robust model...\")\n",
        "    best_params = robust_model.best_params_\n",
        "\n",
        "    robust_final_model = lgb.LGBMRegressor(**best_params, random_state=42, n_jobs=-1)\n",
        "\n",
        "    # CORRECTED: Remove 'verbose' from fit() and use callbacks for early stopping\n",
        "    robust_final_model.fit(\n",
        "        X_train_split,\n",
        "        y_train_split,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_metric='rmse',\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
        "    )\n",
        "\n",
        "    # === ROBUST EVALUATION ===\n",
        "    val_preds = robust_final_model.predict(X_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
        "    mae = mean_absolute_error(y_val, val_preds)\n",
        "    r2 = r2_score(y_val, val_preds)\n",
        "\n",
        "    print(f\"✅ Validation RMSE: {rmse:.2f}\")\n",
        "    print(f\"✅ Validation MAE: {mae:.2f}\")\n",
        "    print(f\"✅ Validation R²: {r2:.6f}\")\n",
        "\n",
        "    # Feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X_train_prepared.columns,\n",
        "        'importance': robust_final_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\n📊 Top 10 Feature Importance:\")\n",
        "    print(feature_importance.head(10).to_string())\n",
        "\n",
        "    # === FINAL ROBUST TRAINING ===\n",
        "    print(\"\\n🎯 Training final robust model on full data...\")\n",
        "    final_robust_model = lgb.LGBMRegressor(**best_params, random_state=42, n_jobs=-1)\n",
        "    final_robust_model.fit(X_train_prepared, y_train)\n",
        "\n",
        "    # === ROBUST PREDICTION ===\n",
        "    test_predictions = final_robust_model.predict(X_test_prepared)\n",
        "\n",
        "    # Post-processing\n",
        "    test_predictions = np.maximum(test_predictions, 1000)\n",
        "    test_predictions = np.round(test_predictions, 2)\n",
        "\n",
        "    # Save robust submission\n",
        "    submission = pd.DataFrame({\n",
        "        'id': test_df['id'],\n",
        "        'price': test_predictions\n",
        "    })\n",
        "    submission.to_csv('ROBUST_lightgbm_submission.csv', index=False)\n",
        "\n",
        "    # Performance report\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"🏆 ROBUST MODEL PERFORMANCE REPORT 🏆\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Final Validation RMSE: ${rmse:,.2f}\")\n",
        "    print(f\"Final Validation MAE: ${mae:,.2f}\")\n",
        "    print(f\"Final Validation R²: {r2:.6f}\")\n",
        "    print(f\"Predictions range: ${test_predictions.min():,.2f} - ${test_predictions.max():,.2f}\")\n",
        "    print(\"✅ ROBUST submission file saved!\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "a-wKoO3mLyoV",
        "outputId": "f993ec72-3c3f-4148-cf8c-3518ad3a7e94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "🚀 Starting ROBUST LightGBM Modeling...\n",
            "🔧 Performing robust feature engineering...\n",
            "⚙️ Preparing robust features...\n",
            "✅ Data types in prepared features:\n",
            "int64      14\n",
            "float64     6\n",
            "Name: count, dtype: int64\n",
            "🎯 Performing efficient hyperparameter tuning...\n",
            "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
            "🏆 Best parameters: {'subsample': 0.9, 'reg_lambda': 0.5, 'reg_alpha': 0.1, 'num_leaves': 31, 'n_estimators': 800, 'min_child_samples': 100, 'max_depth': 8, 'learning_rate': 0.01, 'colsample_bytree': 0.9}\n",
            "🏆 Best CV score: 73267.89\n",
            "\n",
            "🔥 Training robust model...\n",
            "✅ Validation RMSE: 69195.94\n",
            "✅ Validation MAE: 19525.69\n",
            "✅ Validation R²: 0.163858\n",
            "\n",
            "📊 Top 10 Feature Importance:\n",
            "                feature  importance\n",
            "1                milage        3549\n",
            "4        miles_per_year        3124\n",
            "16                model        2939\n",
            "5   engine_displacement        2800\n",
            "0            model_year        2114\n",
            "19          brand_model        2090\n",
            "18         transmission        1973\n",
            "15                brand         978\n",
            "6      engine_cylinders         848\n",
            "10            engine_v8         395\n",
            "\n",
            "🎯 Training final robust model on full data...\n",
            "\n",
            "==================================================\n",
            "🏆 ROBUST MODEL PERFORMANCE REPORT 🏆\n",
            "==================================================\n",
            "Final Validation RMSE: $69,195.94\n",
            "Final Validation MAE: $19,525.69\n",
            "Final Validation R²: 0.163858\n",
            "Predictions range: $6,609.68 - $306,705.87\n",
            "✅ ROBUST submission file saved!\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}